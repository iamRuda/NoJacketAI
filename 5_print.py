"""
Epoch 4/36
161/161 [==============================] - 1058s 7s/step - loss: 3.7856 - accuracy: 0.0801 - val_loss: 3.6622 - val_accuracy: 0.0897
Epoch 5/36
161/161 [==============================] - 1058s 7s/step - loss: 3.5580 - accuracy: 0.1151 - val_loss: 3.5657 - val_accuracy: 0.1026
Epoch 6/36
161/161 [==============================] - 1058s 7s/step - loss: 3.3224 - accuracy: 0.1151 - val_loss: 3.5657 - val_accuracy: 0.1026
Epoch 7/36
161/161 [==============================] - 1058s 7s/step - loss: 3.1473 - accuracy: 0.1151 - val_loss: 3.5657 - val_accuracy: 0.1026
Epoch 8/36
161/161 [==============================] - 1058s 7s/step - loss: 2.9827 - accuracy: 0.1151 - val_loss: 3.5657 - val_accuracy: 0.1026
Epoch 9/36
161/161 [==============================] - 1058s 7s/step - loss: 2.7631 - accuracy: 0.1151 - val_loss: 3.5657 - val_accuracy: 0.1026
Epoch 10/36
161/161 [==============================] - 1058s 7s/step - loss: 2.5486 - accuracy: 0.1151 - val_loss: 3.5657 - val_accuracy: 0.1026
Epoch 11/36
161/161 [==============================] - 1058s 7s/step - loss: 2.3733 - accuracy: 0.1151 - val_loss: 3.5657 - val_accuracy: 0.1026
Epoch 12/36
161/161 [==============================] - 1058s 7s/step - loss: 2.2149 - accuracy: 0.1151 - val_loss: 3.5657 - val_accuracy: 0.1026
Epoch 13/36
161/161 [==============================] - 1058s 7s/step - loss: 2.0281 - accuracy: 0.1151 - val_loss: 3.5657 - val_accuracy: 0.1026
Epoch 14/36
161/161 [==============================] - 1058s 7s/step - loss: 1.7993 - accuracy: 0.1151 - val_loss: 3.5657 - val_accuracy: 0.1026
Epoch 15/36
161/161 [==============================] - 1058s 7s/step - loss: 1.6528 - accuracy: 0.1151 - val_loss: 3.5657 - val_accuracy: 0.1026
Epoch 16/36
161/161 [==============================] - 1058s 7s/step - loss: 1.4856 - accuracy: 0.1151 - val_loss: 3.5657 - val_accuracy: 0.1026
Epoch 17/36
161/161 [==============================] - 1058s 7s/step - loss: 1.3469 - accuracy: 0.1151 - val_loss: 3.5657 - val_accuracy: 0.1026
Epoch 18/36
161/161 [==============================] - 1058s 7s/step - loss: 1.2231 - accuracy: 0.1151 - val_loss: 3.5657 - val_accuracy: 0.1026
Epoch 19/36
161/161 [==============================] - 1058s 7s/step - loss: 1.1429 - accuracy: 0.1151 - val_loss: 3.5657 - val_accuracy: 0.1026
Epoch 20/36
161/161 [==============================] - 1058s 7s/step - loss: 1.0233 - accuracy: 0.1151 - val_loss: 3.5657 - val_accuracy: 0.1026
Epoch 21/36
161/161 [==============================] - 1058s 7s/step - loss: 0.9647 - accuracy: 0.1151 - val_loss: 3.5657 - val_accuracy: 0.1026
Epoch 22/36
161/161 [==============================] - 1058s 7s/step - loss: 0.9139 - accuracy: 0.1151 - val_loss: 3.5657 - val_accuracy: 0.1026
Epoch 23/36
161/161 [==============================] - 1058s 7s/step - loss: 0.8335 - accuracy: 0.1151 - val_loss: 3.5657 - val_accuracy: 0.1026
Epoch 24/36
161/161 [==============================] - 1058s 7s/step - loss: 0.7460 - accuracy: 0.1151 - val_loss: 3.5657 - val_accuracy: 0.1026
Epoch 25/36
161/161 [==============================] - 1058s 7s/step - loss: 0.6538 - accuracy: 0.7271 - val_loss: 0.6751 - val_accuracy: 0.7212
Epoch 26/36
161/161 [==============================] - 1058s 7s/step - loss: 0.5572 - accuracy: 0.7483 - val_loss: 0.5572 - val_accuracy: 0.7397
Epoch 27/36
161/161 [==============================] - 1058s 7s/step - loss: 0.4921 - accuracy: 0.7129 - val_loss: 0.5261 - val_accuracy: 0.7073
Epoch 28/36
161/161 [==============================] - 1058s 7s/step - loss: 0.4278 - accuracy: 0.7389 - val_loss: 0.4472 - val_accuracy: 0.7315
Epoch 29/36
161/161 [==============================] - 1058s 7s/step - loss: 0.3732 - accuracy: 0.7529 - val_loss: 0.3949 - val_accuracy: 0.7473
Epoch 30/36
161/161 [==============================] - 1058s 7s/step - loss: 0.3373 - accuracy: 0.7752 - val_loss: 0.3484 - val_accuracy: 0.7736
Epoch 31/36
161/161 [==============================] - 1058s 7s/step - loss: 0.2994 - accuracy: 0.7961 - val_loss: 0.3163 - val_accuracy: 0.7832
Epoch 32/36
161/161 [==============================] - 1058s 7s/step - loss: 0.2441 - accuracy: 0.8132 - val_loss: 0.2725 - val_accuracy: 0.8075
Epoch 33/36
161/161 [==============================] - 1058s 7s/step - loss: 0.2543 - accuracy: 0.8393 - val_loss: 0.2648 - val_accuracy: 0.8312
Epoch 34/36
161/161 [==============================] - 1058s 7s/step - loss: 0.2381 - accuracy: 0.8536 - val_loss: 0.2381 - val_accuracy: 0.8536
Epoch 35/36
161/161 [==============================] - 1058s 7s/step - loss: 0.2296 - accuracy: 0.8728 - val_loss: 0.2566 - val_accuracy: 0.8679
Epoch 36/36
161/161 [==============================] - 1058s 7s/step - loss: 0.2195 - accuracy: 0.9046 - val_loss: 0.2435 - val_accuracy: 0.9023
"""

import cv2
import os
from tensorflow import keras
import numpy as np

import time
start_time = time.time()

DIR = r'Images'
CATEGORIES = os.listdir(DIR)
print(CATEGORIES)

def image(path):
    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
    if img is None:
        print('Wrong path:', path)
    else:
        new_arr = cv2.resize(img, (256, 256))
        new_arr = np.array(new_arr)
        new_arr = new_arr.reshape(-1, 256, 256, 1)
        return new_arr

model = keras.models.load_model('IndoorSceneRecognition.model(Succeful#1)')
pravilno = 0
n = 0

for category in CATEGORIES:
    path = os.path.join(DIR, category)
    for img in os.listdir(path):
        prediction = model.predict([image(str(path) + "\\" + img)])
        if category == CATEGORIES[prediction.argmax()]:
            pravilno += 1
        n += 1
print("Точность = " + str(pravilno / n * 100) + "% " + "(" + str(pravilno) + "/" + str(n) + ")")

